---
title: "Exercise Movement Prediction"
output: html_document
author: Magdalene Ler
---

# Overview
Human Activity Recognition (HAR) is a key research area in the past few years, which is garnering increasing attention with its pervasive computing research community. There are many potential applications for HAR, like elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises. Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity at a rate never seen before.
 
Six participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different ways:

- exactly according to the specification (Class A)
- throwing the elbows to the front (Class B)
- lifting the dumbbell only halfway (Class C)
- lowering the dumbbell only halfway (Class D); and 
- throwing the hips to the front (Class E).

This report will describe how the captured data are used to identify the important predictors involved in movement prediction of the above classification. It is subsequently used to predict the movement of 20 test cases. The training data is subdivided into two groups: a training data and a validation data to be used for cross-validation.

The training model used for the prediction is Random Forest and was able to achieve >99% accuracy with 0.03% out-of-sample error. It was able to achieve 100% accuracy in predicting 20 test cases in the testing dataset.   

# Downloading Data and Package
## Downloading Package

```{r warning=FALSE, message=FALSE}
library(ggplot2)
library(lattice)
library(caret)
library(foreach)
library(parallel)
library(doParallel)
```

## Downloading Data
### Downloading Training Data
```{r}
csvfile1 <- "pml_training.csv"
if (!file.exists(csvfile1)) {
    url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    download.file(url, destfile = csvfile1)
}
training <- read.csv(csvfile1, na.strings = c("NA","#DIV/0!",""))
```

### Downloading Testing Data
```{r}
csvfile2 <- "pml_testing.csv"
if (!file.exists(csvfile2)) {
    url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download.file(url, destfile = csvfile2)
}
testing <- read.csv(csvfile2, na.strings = c("NA","#DIV/0!",""))
```

# Data Cleansing
The data is cleansed to remove invalid predictors by:

- Removing columns with near zero values
- Removing columns with NA or is empty
- Removing columns that are non-predictors

## Removing columns with near zero values
```{r}
subtraining <-training[, names(training)[!(nzv(training, saveMetrics = T)[, 4])]]
```
## Removing columns with NA or is empty
```{r}
subtraining <-subtraining[, names(subtraining)[sapply(subtraining, function (x) ! (any(is.na(x) | x == "")))]]
```
## Removing columns that are non-predictors
Columns such as serial number are removed as they are not needed in the prediction exercise.
```{r}
subtraining <- subtraining[,-1]
subtraining <- subtraining[, c(1:3, 5:58)]
```

# Split the dataset to be used for Cross Validation
A subset is separated out from the training dataset in order to be used for validation. 
The cross validation dataset is used to compare the model created through the training dataset. 
```{r}
partitions <- createDataPartition(subtraining$classe, p = 0.6, list = FALSE)
trainingDataSet <- subtraining[partitions,]
validationDataSet <- subtraining[-partitions,]
```

# Build Prediction Model
The training dataset from the previous section is used to create the prediction model using Random Forest. 
The CPU Resources is set to run in parallel to maximize the usage of all CPU Cores.

```{r}
# Check if model file exists
model <- "modelFit.RData"
if (!file.exists(model)) {

    # set up the parallel clusters  
    cl <- makeCluster(detectCores() - 1)
    registerDoParallel(cl)
    
    modelFit <- train(trainingDataSet$classe ~ ., method = "rf", data = trainingDataSet)
    save(modelFit, file = "modelFit.RData")
    stopCluster(cl)
} else {
    # existing model exists from previous run, load it and use it.  
    load(file = "modelFit.RData", verbose = FALSE)
}
```
# Accuracy and Sample Error Measurement of the Prediction Model
Confusion Matrix is ran against the prediction results from various model fitting functions of both training data set and validation data set to determine its accuracy and sample error.

## Confusion Matrix for Training Data Set
From the training dataset, the accuracy is very high at >99% with a sample error of 0.0003.
```{r warning=FALSE, message=FALSE}
trainingPrediction <- predict(modelFit, trainingDataSet)
confusionMatrix(trainingPrediction, trainingDataSet$classe)
```

## Confusion Matrix for Validation Data Set
From the validation dataset, the accuracy is also very high at >99% with an out-of-sample error of 0.0003.
```{r warning=FALSE, message=FALSE}
validationPrediction <- predict(modelFit, validationDataSet)
confusionMatrix(validationPrediction, validationDataSet$classe)
```
 
## Out-of-Bag (OOB) Estimated Error
The OOB Estimated Error is 0.13%, however since we observe the following:

- a consistent accuracy of >99% observed for both the training dataset and validation dataset
- cross-validation out-of-sample error of 0.03% at confidence interval of (0.9993, 0.9999)

It is safe to apply the prediction model to the 20 test cases in the testing dataset to predict the classe.

```{r}
modelFit$finalModel
```

# Important Predictors for the Prediction Model
Below is a list of the important predictors used in the Random Forest prediction model that facilitates it in achieving >99% accuracy.
```{r}
varImp(modelFit)
```

# Applying Prediction Model to Testing Dataset
```{r}
testingPrediction <- predict(modelFit, testing)
testingPrediction
```

# Conclusion
The prediction model predicted the 20 test cases with 100% accuracy.
